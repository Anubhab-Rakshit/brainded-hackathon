# ReelSense: System Architecture & Workflow
## For Presentation Slides (PPT)

### 1. The "ReelSense" Logic Flow (Mermaid Diagram)
*Copy this code into a Mermaid viewer to generate the high-level architecture diagram.*

```mermaid
graph TD
    %% Nodes
    User[ðŸ‘¤ User Interactions] --> Data[DATA PROCESSING LAYER]
    Data --> |Sequence Data| SASRec[ðŸ§  Context-Aware SASRec]
    Data --> |Graph Data| GCN[ðŸ•¸ï¸ LightGCN (SOTA)]
    Data --> |Rating Matrix| SVD[ðŸ’¾ SVD (Memory)]
    
    subgraph "The Holy Trinity (Ensemble)"
        SASRec --> |"Predicts Intent"| Scores1[Score A]
        GCN --> |"Finds Connections"| Scores2[Score B]
        SVD --> |"Matches Preferences"| Scores3[Score C]
    end
    
    Scores1 & Scores2 & Scores3 --> Ensemble[âš–ï¸ ENSEMBLE AGGREGATOR]
    Ensemble --> |Raw Top 50| MMR[ðŸŽ¨ MMR DIVERSITY FILTER]
    MMR --> |"Re-Ranking"| Final[âœ¨ Final Top 10 Recommendations]

    style SASRec fill:#ff9900,stroke:#333,stroke-width:2px,color:white
    style GCN fill:#00cc99,stroke:#333,stroke-width:2px,color:white
    style MMR fill:#9966ff,stroke:#333,stroke-width:2px,color:white
```

---

### 2. Step-by-Step Workflow Description
*Use these bullet points for your "How It Works" slide.*

#### **Phase 1: Ingestion & Understanding**
*   **Input**: We take raw MovieLens data (Users, Movies, Timestamps, Genres).
*   **Transformation**:
    *   **Time-Sorting**: We order user history to understand the *sequence* (Movie A $\to$ Movie B).
    *   **Graph-Building**: We connect Users and Movies if a rating exists, creating a giant social graph.

#### **Phase 2: The "Trinity" Processing (Parallel Computing)**
Three models run simultaneously to capture different aspects of human behavior:
1.  **SVD (The Historian)**: Looks at past ratings to find long-term taste (e.g., "Anubhab likes Sci-Fi").
2.  **LightGCN (The Explorer)**: Explores the graph. "People who liked Interstellar *also* linked to users who liked The Martian."
3.  **Context-Aware SASRec (The Mind Reader)**: Analyzes the *immediate* sequence. "You just watched *Iron Man 1* and *Iron Man 2*. The next logical step is *The Avengers* (Action/Superhero Context)."

#### **Phase 3: The Decision Layer**
*   **Ensemble**: We average the confidence scores from all three models.
    *   *Why?* If SASRec is unsure (Cold Start), LightGCN fills the gap. If LightGCN is too broad, SVD grounds it.
*   **MMR (Diversity Guardrail)**:
    *   We take the Top 50 candidates.
    *   We pick the #1 best match.
    *   For #2, we ask: "Is this too similar to #1?" If yes, we skip it.
    *   **Result**: We show *The Avengers*, but then maybe *Inception* instead of *Captain America*, keeping the list fresh.

---

### 3. Implementation Workflow (How we ran it)
*Use this for the "Engineering Challenges" slide.*

1.  **Optimization**: Standard Python was too slow for the Transformer loop.
2.  **Hardware Acceleration**: We enabled **MPS (Metal Performance Shaders)** on Apple Silicon.
3.  **Result**: Training time reduced from **60 minutes to 5 minutes**, allowing for rapid tuning during the hackathon.

---

*Generated by ReelSense Team*
