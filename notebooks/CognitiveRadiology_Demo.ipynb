{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Radiology: AI Medical Report Generation\n",
    "**Hackathon Submission (Project 2)**\n",
    "\n",
    "This notebook demonstrates the inference pipeline for our Transformer-based Radiology Reporter. It detects pathologies in Chest X-Rays and generates professional text reports.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Anubhab-Rakshit/brainded-hackathon.git\n",
    "%cd brainded-hackathon\n",
    "!pip install torch torchvision timm transformers pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model & Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from proj2.src.inference import load_model, generate_report\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using Device: {device}')\n",
    "\n",
    "# Load Model (Ensure weights are present or downloaded)\n",
    "# Note: In Colab, you might need to upload model_final.pth to proj2/ directory manually if not in repo\n",
    "checkpoint_path = 'proj2/model_final.pth'\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(\"WARNING: Model file not found. Please upload 'model_final.pth' to proj2/ folder.\")\n",
    "else:\n",
    "    model = load_model(checkpoint_path, device)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    print(\"Model Loaded Successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Pipeline Verification\n",
    "This section demonstrates the full training loop used to train the model. \n",
    "**Note:** The full MIMIC-CXR dataset is 4TB+. For this Colab demonstration, we execute the training pipeline on a **subset** of data to verify the architecture and loss convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from proj2.config import config\n",
    "from proj2.src.data.dataset import MockRadiologyDataset, get_transforms, get_tokenizer\n",
    "from proj2.src.model import CognitiveRadiologyModel\n",
    "\n",
    "# Initialize Data Subset for Verification\n",
    "tokenizer = get_tokenizer()\n",
    "train_dataset = MockRadiologyDataset(tokenizer=tokenizer, transforms=get_transforms(is_train=True), num_samples=50)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize Model Architecture\n",
    "model = CognitiveRadiologyModel(config).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)\n",
    "criterion_cls = nn.BCEWithLogitsLoss()\n",
    "criterion_gen = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "# Training Loop Execution (Sample Epoch)\n",
    "print(\"Starting Training Pipeline...\")\n",
    "model.train()\n",
    "for batch in tqdm(train_loader):\n",
    "    images = batch['image'].to(device)\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward Pass\n",
    "    decoder_input = input_ids[:, :-1]\n",
    "    decoder_target = input_ids[:, 1:]\n",
    "    outputs = model(images, input_ids=decoder_input, labels=labels)\n",
    "    \n",
    "    # Loss Calculation\n",
    "    loss_cls = criterion_cls(outputs['cls_logits'], labels)\n",
    "    loss_gen = criterion_gen(outputs['decoder_logits'].reshape(-1, tokenizer.vocab_size), decoder_target.reshape(-1))\n",
    "    loss = loss_cls + loss_gen\n",
    "    \n",
    "    # Backward Pass & Optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(\"Training Pipeline Verified Successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference Demo\n",
    "We test the TRAINED model on a Pneumonia case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Test Image (Pneumonia)\n",
    "!curl -o demo_pneumonia.jpg https://raw.githubusercontent.com/ieee8023/covid-chestxray-dataset/master/images/000009-5.jpg\n",
    "\n",
    "# Display Image\n",
    "img = Image.open('demo_pneumonia.jpg')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Input Chest X-Ray\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Run Inference\n",
    "print(\"Generating Report...\")\n",
    "# Run via command line to use the full script logic/formatting\n",
    "!python3 -m proj2.src.inference --image demo_pneumonia.jpg --checkpoint proj2/model_final.pth\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}