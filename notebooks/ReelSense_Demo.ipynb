{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ReelSense: Explainable Movie Recommender\n",
                "\n",
                "This notebook demonstrates the ReelSense recommender system pipeline, including:\n",
                "1. Data Loading & Preprocessing\n",
                "2. Model Training (SVD, Hybrid, Neural CF, LightGCN, SASRec)\n",
                "3. Ensemble Creation\n",
                "4. Diversity Optimization (MMR)\n",
                "5. Explainability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
                "\n",
                "from src.data import DataLoader\n",
                "from src.recommenders import PopularityRecommender, CollaborativeRecommender, SVDRecommender, ContentRecommender, HybridRecommender, NeuralCFRecommender, DiversityRecommender, LightGCNRecommender, EnsembleRecommender, SASRecRecommender\n",
                "from src.evaluation import precision_at_k, recall_at_k, ndcg_at_k, coverage\n",
                "from src.explainability import Explainer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Split Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = \"../ml-latest-small\"\n",
                "loader = DataLoader(data_path)\n",
                "loader.load_data()\n",
                "loader.preprocess()\n",
                "\n",
                "train_df, test_df = loader.get_train_test_split(method='leave_last_n', n=1)\n",
                "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train Models (Including SOTA Transformers)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_items = loader.movies['movieId'].unique()\n",
                "\n",
                "models = {\n",
                "    \"Popularity\": PopularityRecommender(),\n",
                "    \"SVD\": SVDRecommender(n_components=20),\n",
                "    \"Hybrid (SVD+Content)\": HybridRecommender(SVDRecommender(n_components=20), ContentRecommender(), alpha=0.3),\n",
                "    \"Neural CF (NeuMF)\": NeuralCFRecommender(embedding_dim=32, n_epochs=10),\n",
                "    \"LightGCN (SOTA)\": LightGCNRecommender(n_epochs=50),\n",
                "    \"SASRec (Transformer)\": SASRecRecommender(n_epochs=10, embedding_dim=64, n_heads=2),\n",
                "    \"Diversity Optimized (MMR)\": DiversityRecommender(HybridRecommender(SVDRecommender(n_components=20), ContentRecommender(), alpha=0.3), lambda_param=0.6)\n",
                "}\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f\"Training {name}...\")\n",
                "    if \"MMR\" in name:\n",
                "         model.fit(train_df, loader.movies, tags_df=loader.tags)\n",
                "    elif \"Hybrid\" in name:\n",
                "        model.fit(train_df, loader.movies, loader.tags)\n",
                "    else:\n",
                "        model.fit(train_df)\n",
                "\n",
                "# Create Ensemble\n",
                "print(\"Creating Ensemble...\")\n",
                "models[\"Ensemble (Trinity)\"] = EnsembleRecommender({\n",
                "    \"SVD\": models[\"SVD\"],\n",
                "    \"LightGCN\": models[\"LightGCN (SOTA)\"],\n",
                "    \"SASRec\": models[\"SASRec (Transformer)\"]\n",
                "}, weights={\"SVD\": 0.3, \"LightGCN\": 0.3, \"SASRec\": 0.4})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "\n",
                "def evaluate(model, test_df, k=10):\n",
                "    precisions, recs = [], []\n",
                "    test_users = test_df['userId'].unique()\n",
                "    \n",
                "    for uid in tqdm(test_users):\n",
                "        truth = test_df[test_df['userId'] == uid]['movieId'].tolist()\n",
                "        rec_items = model.recommend(uid, n=k)\n",
                "        if not rec_items: rec_items = []\n",
                "        recs.append(rec_items)\n",
                "        precisions.append(precision_at_k(rec_items, truth, k))\n",
                "        \n",
                "    return np.mean(precisions), coverage(recs, all_items)\n",
                "\n",
                "print(\"{:<30} {:<15} {:<15}\".format(\"Model\", \"Precision@10\", \"Coverage\"))\n",
                "for name, model in models.items():\n",
                "    p, c = evaluate(model, test_df)\n",
                "    print(\"{:<30} {:<15.4f} {:<15.4f}\".format(name, p, c))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Explainability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "explainer = Explainer(loader, train_df)\n",
                "user_id = test_df['userId'].iloc[0]\n",
                "recs = models['Diversity Optimized (MMR)'].recommend(user_id, n=3)\n",
                "\n",
                "print(f\"User {user_id} Recommendations (Diversity Optimized):\")\n",
                "for mid in recs:\n",
                "    title = loader.movies[loader.movies['movieId'] == mid]['title'].iloc[0]\n",
                "    reason = explainer.explain(user_id, mid)\n",
                "    print(f\"- {title}\\n  {reason}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}